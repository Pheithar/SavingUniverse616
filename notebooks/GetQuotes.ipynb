{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Character quotes\n",
    "\n",
    "For doing sentiment analyse, we propose the use of the quotes of each character. For that we need to compilate all the quotes from each character.\n",
    "\n",
    "That's fine, as inside the wiki, each character has a 'Quotes' page wich can be accessed by `Category:{Name}/Quotes` (https://marvel.fandom.com/wiki/Category:Peter_Parker_(Earth-616)/Quotes). Easy right?. Well, even tho that page exist, if you try to make a query to it, you will most likely get `{{Quotes}}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\r\n",
    "import urllib.request\r\n",
    "\r\n",
    "import re\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import utils\r\n",
    "import os\r\n",
    "\r\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_df = pd.read_csv(\"../data/marvel_characters.csv\", index_col=0)\r\n",
    "char_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_quotes(titles: list):\r\n",
    "  baseurl = \"https://marvel.fandom.com/api.php?\"\r\n",
    "  action = \"action=query\"\r\n",
    "  title = f\"titles={'|'.join([urllib.parse.quote_plus(title.replace(' ', '_')) for title in titles])}\"\r\n",
    "   \r\n",
    "  content = \"prop=revisions&rvprop=content&rvslots=*\"\r\n",
    "  dataformat =\"format=json\"\r\n",
    "\r\n",
    "  query = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\r\n",
    "\r\n",
    "  wikiresponse = urllib.request.urlopen(query)\r\n",
    "  wikidata = wikiresponse.read()\r\n",
    "  wikitext = wikidata.decode('utf-8')\r\n",
    "  return json.loads(wikitext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading all quotes from the characters in  ``data/marvel_characters.csv``\r\n",
    "\r\n",
    "To do this we multithread to do simultanious queries, and query for 50 titles at a time, as that is the max amount of titles allowed, and the background DB on the wiki page is much faster, than the internet connection between our machine and theirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_path = \"../data/character_quotes/\"\r\n",
    "\r\n",
    "def get_character_quotes(name: str):\r\n",
    "  # This is a little bit hacky, but works\r\n",
    "  cmcontinue_text = \"\"\r\n",
    "  quote_titles = []\r\n",
    "\r\n",
    "  # Breaks when there are no more cm_continues\r\n",
    "  while True:\r\n",
    "    baseurl = \"https://marvel.fandom.com/api.php?\"\r\n",
    "    args = {\r\n",
    "      \"action\"      : \"action=query&list=categorymembers\",\r\n",
    "      \"q_title\"     : \"cmtitle=Category:{}/Quotes\".format(urllib.parse.quote_plus(name.replace(\" \", \"_\"))),\r\n",
    "      \"content\"     : \"prop=revisions&rvprop=content&rvslots=*\",\r\n",
    "      \"dataformat\"  : \"format=json\",\r\n",
    "      \"cmcontinue\"  :  \"cmlimit=max&cmcontinue={}\".format(cmcontinue_text),\r\n",
    "    }\r\n",
    "    \r\n",
    "    query = f\"{baseurl}{'&'.join(args.values())}\"\r\n",
    "\r\n",
    "    wikiresponse = urllib.request.urlopen(query)\r\n",
    "    wikitext = wikiresponse.read().decode('utf-8')\r\n",
    "    wiki_json = json.loads(wikitext)\r\n",
    "    \r\n",
    "    quote_titles += [page[\"title\"] for page in wiki_json[\"query\"][\"categorymembers\"]]\r\n",
    "\r\n",
    "    if \"continue\" in list(wiki_json.keys()):\r\n",
    "      cmcontinue_text = wiki_json[\"continue\"][\"cmcontinue\"]\r\n",
    "    else: break\r\n",
    "  \r\n",
    "  quote_title_chunks = utils.generate_chunks(quote_titles)\r\n",
    "  quotes = []\r\n",
    "\r\n",
    "  for chunk in quote_title_chunks:\r\n",
    "    quote_data = search_quotes(chunk)\r\n",
    "    for content in quote_data[\"query\"][\"pages\"].values():\r\n",
    "      content  = content[\"revisions\"][-1][\"slots\"][\"main\"][\"*\"]\r\n",
    "      quotes += re.findall(r\"Quotation.*?= (.*?)\\n\", content)\r\n",
    "  \r\n",
    "  filename = utils.generate_filename(name)\r\n",
    "  with open(f\"{quote_path}{filename}.json\", \"w\") as f:\r\n",
    "    json.dump(quotes, f, indent = 4)\r\n",
    "\r\n",
    "def get_chunk_quotes(chunk: list):\r\n",
    "  for name in chunk:\r\n",
    "    get_character_quotes(name)\r\n",
    "  return\r\n",
    "\r\n",
    "def get_quotes(names: list, max_workers=16):\r\n",
    "  files = set(os.listdir(quote_path))\r\n",
    "  missing_names = list(\r\n",
    "    filter(lambda x: f\"{utils.generate_filename(x)}.json\" not in files,\r\n",
    "    names)\r\n",
    "  )\r\n",
    "\r\n",
    "  if len(missing_names) == 0:\r\n",
    "    print(\"No missign quotes found ðŸ˜Š\")\r\n",
    "    return\r\n",
    "  \r\n",
    "  chunks = utils.generate_chunks(missing_names)\r\n",
    "  print (f\"Generated {len(chunks)} chunks!\")\r\n",
    "  with tqdm(total=len(chunks)) as pbar:\r\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\r\n",
    "      futures = [ex.submit(get_chunk_quotes, chunk)\r\n",
    "                  for chunk in chunks]\r\n",
    "      for future in as_completed(futures):\r\n",
    "        pbar.update(1)\r\n",
    "\r\n",
    "\r\n",
    "get_quotes(char_df.title.values , max_workers=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://marvel.fandom.com/api.php?action=query&list=categorymembers&cmtitle=Category:Peter_Parker_(Earth-616)/Quotes&cmlimit=500&prop=revisions&rvprop=content&rvslots=*&format=json"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3405df15e4953545831bbb8174ce89dd7632c146c43537a8990c777f42b240d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}