{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Team Assembler\n",
    "\n",
    "![header](../images/The_Marvel_Universe.png)\n",
    "\n",
    "In this first notebook we are going to substract all the characters from different Marvel heroes and villain teams to create the graph that is going to be used on the project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "import urllib.request\r\n",
    "\r\n",
    "import re\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_json(title):\r\n",
    "  baseurl = \"https://marvel.fandom.com/api.php?\"\r\n",
    "  action = \"action=query\"\r\n",
    "  title = \"titles={}\".format(urllib.parse.quote_plus(title.replace(\" \", \"_\")))\r\n",
    "   \r\n",
    "  content = \"prop=revisions&rvprop=content&rvslots=*\"\r\n",
    "  dataformat =\"format=json\"\r\n",
    "\r\n",
    "  query = \"{}{}&{}&{}&{}\".format(baseurl, action, content, title, dataformat)\r\n",
    "    \r\n",
    "  wikiresponse = urllib.request.urlopen(query)\r\n",
    "  wikidata = wikiresponse.read()\r\n",
    "  wikitext = wikidata.decode('utf-8')\r\n",
    "    \r\n",
    "  return json.loads(wikitext)\r\n",
    "\r\n",
    "def displayWiki(wiki):\r\n",
    "    code = str(list(wiki[\"query\"][\"pages\"].keys())[0])\r\n",
    "    title = wiki[\"query\"][\"pages\"][code][\"title\"]\r\n",
    "    content = wiki[\"query\"][\"pages\"][code][\"revisions\"][0][\"slots\"][\"main\"][\"*\"]\r\n",
    "    return title, content"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Teams\n",
    "\n",
    "Instead of getting every single character from Marvel, we are going to work with a small subset. Why? Well, first of all, in the Marvel wiki there are more than 30.000 characters. Recopilate and process all that information would take a long time, and most of those characterrs are secondary characters that do not give much information.The second reason, and the deciding factor was that there is no easy way to get the link to all the characters from the wiki."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "displayWiki(get_json(\"Category:Characters\"))[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "displayWiki(get_json(\"Category:Earth-616/Characters\"))[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As can be seen in the previous cells, doing a query over the character wiki page, it does not return any link or information about any character."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some background\n",
    "\n",
    "For those of you that are not huge Marvel nerd fans, you will probably appreciate some background to be able to understand the data a bit more.\n",
    "\n",
    "Marvel is divided in many (many) universes, in the Marveel multiverse (it makes sense right). This is done to allow any Marvel writer some creative freedom. If someone wants to make a story where Spider-Man is a cartoony pig, well, they can do it ([Spider-Ham](https://marvel.fandom.com/wiki/Peter_Porker_(Earth-8311))), in a different universe, so it does not collide with the main characters in other universes.\n",
    "\n",
    "The main universe, where most relevant events and different, and more canon stories occur, is the universe called *Earth-616*, and is the one we are going to use for our analysis. Is where the most known stories happen, and where there are more superheores and supervillains.\n",
    "\n",
    "Ok, but what teams did we select. We tried to get the most famous ones, both of heores and villains, so we could get more characters from it, and we could get the most famous ones too."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "teams = None\n",
    "with open(\"../data/teams.txt\", \"r\") as f:\n",
    "  teams = f.read().split(\"\\n\")[:-1]\n",
    "teams"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All links are either `[[link]]` or `[[link|known_as]]`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "regex_links = r\"\\[\\[(.*?)(?:|\\|.*?)\\]\\]\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Every team has a similar structure:\n",
    "\n",
    "```\n",
    "{{Marvel Database:Team Template\n",
    "| Title                   = \n",
    "| Image                   = \n",
    "| ImageSize               = \n",
    "| Name                    = \n",
    "| EditorialNames          = \n",
    "| Aliases                 = \n",
    "| Status                  = \n",
    "| Identity                = \n",
    "| Reality                 = \n",
    "| BaseOfOperations        = \n",
    "| Leaders                 = \n",
    "| CurrentMembers          = \n",
    "| FormerMembers           = \n",
    "| Allies                  = \n",
    "| Enemies                 = \n",
    "| Origin                  = \n",
    "| PlaceOfFormation        = \n",
    "| PlaceOfDissolution      = \n",
    "| Creators                = \n",
    "| First                   =\n",
    "| Last                    = \n",
    " \n",
    " ...\n",
    " ...\n",
    " ...\n",
    " }}\n",
    "```\n",
    "\n",
    "We want to obtain the characters that are leaders of a group, those that are current members, those that are former members, allies and enemies. And, just in case those are useful too, those that appear on the subsequent text.\n",
    "\n",
    "That's why we divide in groups of information, and get the links from them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def createDataFrame(teams):\r\n",
    "  df = pd.DataFrame(columns=[\"team_name\", \"leaders\", \"current_members\",\r\n",
    "                             \"former_members\", \"allies\", \"enemies\",\r\n",
    "                             \"additional_links\"]\r\n",
    "                   )\r\n",
    "  \r\n",
    "  for team in tqdm(teams):\r\n",
    "    content = displayWiki(get_json(team))[1]\r\n",
    "    header = re.split(r\"\\| First\", content)[0]\r\n",
    "    web_content = re.split(r\"\\| Origin \", content)[1]\r\n",
    "\r\n",
    "    name = re.sub(\" \\(Earth-.*\", \"\", team)\r\n",
    "    \r\n",
    "    leaders_raw = re.findall(r\"Leaders.*?\\| CurrentMembers\", header, flags=re.DOTALL)[0]\r\n",
    "    leaders = re.findall(regex_links, leaders_raw)\r\n",
    "\r\n",
    "    current_member_raw = re.findall(r\"\\| CurrentMembers.*?\\| FormerMembers\", header, flags=re.DOTALL)[0]\r\n",
    "    current_member = re.findall(regex_links, current_member_raw)\r\n",
    "\r\n",
    "    former_member_raw = re.findall(r\"\\| FormerMembers.*?\\| Allies\", header, flags=re.DOTALL)[0]\r\n",
    "    former_member = re.findall(regex_links, former_member_raw)\r\n",
    "\r\n",
    "    allies_raw = re.findall(r\"\\| Allies.*?\\| Enemies\", header, flags=re.DOTALL)[0]\r\n",
    "    allies = re.findall(regex_links, allies_raw)\r\n",
    "\r\n",
    "    enemies_raw = re.findall(r\"\\| Enemies.*?\\| Origin\", header, flags=re.DOTALL)[0]\r\n",
    "    enemies = re.findall(regex_links, enemies_raw)\r\n",
    "    \r\n",
    "    additional_links = re.findall(regex_links, web_content)\r\n",
    "  \r\n",
    "    with open(\"../data/teams/\"+team.replace(\" \", \"_\")+\".txt\", \"w\") as f:\r\n",
    "      f.write(content)\r\n",
    "  \r\n",
    "    row = {\r\n",
    "      \"team_name\"       : name,\r\n",
    "      \"leaders\"         : leaders,\r\n",
    "      \"current_members\" : current_member,\r\n",
    "      \"former_members\"  : former_member,\r\n",
    "      \"allies\"          : allies,\r\n",
    "      \"enemies\"         : enemies,\r\n",
    "      \"additional_links\": additional_links\r\n",
    "    }\r\n",
    "    \r\n",
    "    df = df.append(row, ignore_index=True)\r\n",
    "  \r\n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "marvel_df = createDataFrame(teams)\r\n",
    "marvel_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Characters\n",
    "\n",
    "Ok, now that we have each team with their characters, it's time to get each character. That would be straight forward if it wasn't because the data is not clean. As we have gotten every single link, some of them reference somethings that are nor characters, such as other teams, races or concepts."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "characters_df = pd.DataFrame(columns=[\"name\", \"teams\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_characters = list()\r\n",
    "\r\n",
    "for i, row in marvel_df.iterrows():\r\n",
    "  all_characters += [*row.leaders, *row.current_members, *row.former_members, *row.allies, *row.enemies]\r\n",
    "\r\n",
    "characters_df = pd.DataFrame(list(set(all_characters)), columns=[\"name\"])\r\n",
    "characters_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luckily, the characters have a template unique, that looks like:\n",
    "  \n",
    "```\n",
    "{{Marvel Database:Character Template\n",
    "| Image                   = \n",
    "| Name                    = \n",
    "| CurrentAlias            = \n",
    "| Aliases                 = \n",
    "| Affiliation             = \n",
    "| Relatives               = \n",
    "| MaritalStatus           = \n",
    "| CharRef                 = \n",
    "| Gender                  = \n",
    "| Height                  = \n",
    "| Weight                  = \n",
    "| Eyes                    = \n",
    "| Hair                    = \n",
    "| UnusualFeatures         = \n",
    "  ...\n",
    "  ...\n",
    "}}\n",
    "```\n",
    "Ok, this looks similar to the teams template, but what we have to look at is the keyword `CharRef`. This keyword is unique for the characters (as well as `Gender`, `Height`, `Weight`, `Eyes`, `Hair` and `UnusualFeatures`)\n",
    "\n",
    "Knowing this, we can decide if a link is a character, or other thing. At the same time, because we are looking at their wiki content, we can get the links they reference."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def getContent(row):\r\n",
    "  regex = r'\\/|\\\"|\\:|\\*| '\r\n",
    "  \r\n",
    "  new_name = re.sub(regex, \"_\", row[\"name\"])\r\n",
    "  \r\n",
    "  try:\r\n",
    "    content = displayWiki(get_json(row[\"name\"]))[1]\r\n",
    "\r\n",
    "    isCharacter = len(re.findall(r\"\\| CharRef\", content)) > 0\r\n",
    "    links = list()\r\n",
    "    \r\n",
    "    with open(\"../data/characters/\" + new_name + \".txt\", \"w\") as f:\r\n",
    "      f.write(content)\r\n",
    "\r\n",
    "    if isCharacter:\r\n",
    "      links = re.findall(regex_links, content)\r\n",
    "      links = [re.sub(regex, \"_\", x) for x in links]\r\n",
    "      \r\n",
    "  except KeyError:    \r\n",
    "    links = list()\r\n",
    "    isCharacter = False\r\n",
    "    \r\n",
    "    \r\n",
    "  return pd.Series([new_name, isCharacter, links])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "characters_df[[\"name\", \"is_character\", \"links\"]] = characters_df.progress_apply(getContent, axis=1)\r\n",
    "\r\n",
    "characters_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "characters_df = characters_df[characters_df[\"is_character\"]].drop(columns=[\"is_character\"])\r\n",
    "characters_df.reset_index(drop=True)\r\n",
    "\r\n",
    "characters_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def replace_names(row):\r\n",
    "  characters = [row.leaders, row.current_members, row.former_members,\r\n",
    "                row.allies, row.enemies, row.additional_links]\r\n",
    "  \r\n",
    "  regex = r'\\/|\\\"|\\:|\\*| '\r\n",
    "  \r\n",
    "  new_characters = list()\r\n",
    "  \r\n",
    "  for i, character_list in enumerate(characters):\r\n",
    "    new_characters.append(list())\r\n",
    "    for character in character_list:\r\n",
    "      new_characters[i].append(re.sub(regex, \"_\", character))\r\n",
    "  \r\n",
    "  return pd.Series(new_characters)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning\n",
    "\n",
    "After we have the links, is necessary to clean those links that do not reference any characters from the links from both datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_real_links(row):\r\n",
    "  links = [x for x in row.links if x in characters_df[\"name\"].values]\r\n",
    "  links = list(set(links))\r\n",
    "  \r\n",
    "  return pd.Series([links, len(links)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "characters_df[[\"links\", \"number_links\"]] = characters_df.progress_apply(get_real_links, axis=1)\r\n",
    "\r\n",
    "characters_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "marvel_df[[\"leaders\", \"current_members\",\r\n",
    "           \"former_members\", \"allies\", \r\n",
    "           \"enemies\", \"additional_links\"]] = marvel_df.progress_apply(replace_names, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clear_dataset(row):\r\n",
    "\r\n",
    "  leaders = [x for x in row.leaders if x in characters_df[\"name\"].values]\r\n",
    "  current_members = [x for x in row.current_members if x in characters_df[\"name\"].values]\r\n",
    "  former_members = [x for x in row.former_members if x in characters_df[\"name\"].values]\r\n",
    "  allies = [x for x in row.allies if x in characters_df[\"name\"].values]\r\n",
    "  enemies = [x for x in row.enemies if x in characters_df[\"name\"].values]\r\n",
    "  additional_links = [x for x in row.additional_links if x in characters_df[\"name\"].values]\r\n",
    "  \r\n",
    "  return pd.Series([leaders, current_members, former_members, allies, enemies, additional_links])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "marvel_df[[\"leaders\", \"current_members\",\r\n",
    "           \"former_members\", \"allies\",\r\n",
    "           \"enemies\", \"additional_links\"]] = marvel_df.progress_apply(clear_dataset, axis=1)\r\n",
    "\r\n",
    "marvel_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mixin the information from both datasets\n",
    "\n",
    "Now we want to get wich team does any characterr belongs to, is ally or enemy to, so we could build more meaningfull relations after."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def belongs_to(team, character_name, column):\r\n",
    "  members = marvel_df.loc[marvel_df['team_name'] == team][column]\r\n",
    "  return character_name in members.values[0]\r\n",
    "\r\n",
    "def get_team_info(row):\r\n",
    "  \r\n",
    "  leader = []\r\n",
    "  member = []\r\n",
    "  ally = []\r\n",
    "  enemy = []\r\n",
    "  \r\n",
    "  for _, team_row in marvel_df.iterrows():\r\n",
    "    if belongs_to(team_row[\"team_name\"], row[\"name\"], \"leaders\"):\r\n",
    "      leader.append(team_row[\"team_name\"])\r\n",
    "    if belongs_to(team_row[\"team_name\"], row[\"name\"], \"current_members\"):\r\n",
    "      member.append(team_row[\"team_name\"])\r\n",
    "    if belongs_to(team_row[\"team_name\"], row[\"name\"], \"former_members\"):\r\n",
    "      member.append(team_row[\"team_name\"])\r\n",
    "    if belongs_to(team_row[\"team_name\"], row[\"name\"], \"allies\"):\r\n",
    "      ally.append(team_row[\"team_name\"])\r\n",
    "    if belongs_to(team_row[\"team_name\"], row[\"name\"], \"enemies\"):\r\n",
    "      enemy.append(team_row[\"team_name\"])\r\n",
    "  \r\n",
    "  return pd.Series([leader, member, ally, enemy])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "characters_df[[\"leader\", \"member\", \"ally\", \"enemy\"]] = characters_df.progress_apply(get_team_info, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "characters_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the datasets\n",
    "\n",
    "Now that the entries are somewhat clear, we can save them"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "marvel_df.to_csv(\"../data/marvel_teams.csv\", index=False)\r\n",
    "characters_df.to_csv(\"../data/marvel_characters.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tqdm.notebook as tqdm\r\n",
    "import time\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "total = 29998\r\n",
    "cur = len(os.listdir(\"../data/character_content\"))\r\n",
    "\r\n",
    "while True:\r\n",
    "    cur = len(os.listdir(\"../data/character_content\"))\r\n",
    "    print(cur, end=\"->\")\r\n",
    "    if cur == total:\r\n",
    "        break\r\n",
    "\r\n",
    "    time.sleep(2)\r\n",
    "\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "8506575580bf2c4cdf5283b234470f5904dd155f436b1a601ec65be85c4bd581"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}